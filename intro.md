# AI Study Group



- Topic 1 Mathematical theory of deep learning; Implement MLP from scratch (Numpy)
   - Architecture of MLP
    - Forward and backward propagation
    - Optimization Algorithms
    - Regularization techniques

- Topic 2 CNN; RNN; LSTM
- Topic 3 Transformer and self-attention
    - Derivation of self-attention mechanism: Q, K, V matrices
    - Multi-head attention and positional encoding
- Topic 4 Computer vision â€“ classification, detection, and generation
    - VGG; ResNet
    - Faster R-CNN; YOLO; SSD
    - DDPM; Stable Diffusion

- Ad-hoc topic
    - Docker & GCP
    - Multi-modal Learning
    - Distributed and Large-Scale Training

References

1. Petersen, P., & Zech, J. (2025). [Mathematical theory of deep learning](https://arxiv.org/abs/2407.18384).
2. [Machine learning, in NumPy](https://github.com/ddbourgin/numpy-ml)
3. Wu Y. (2024). [Machine Learning Methods](http://www.stat.ucla.edu/~ywu/MLBOOK2024.pdf)


```{tableofcontents}
```
